{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import pyprind\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import model_zoo\n",
    "import dataloader\n",
    "import scikitplot as skplt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=5, start_in_channels=64):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.current_in_channels = start_in_channels\n",
    "        \n",
    "        self.first = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                3, self.current_in_channels,\n",
    "                kernel_size=7, stride=2, padding=3, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(self.current_in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.layers = layers\n",
    "        channels = self.current_in_channels\n",
    "        for i, l in enumerate(layers):\n",
    "            setattr(self, 'layer'+str(i+1), \n",
    "                    self._make_layer(block, channels, l, stride=(2 if i!=0 else 1) ))\n",
    "            channels*=2\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(self.current_in_channels, num_classes)\n",
    "            \n",
    "    def _make_layer(self, block, in_channels, blocks, stride=1):\n",
    "        downsample=None\n",
    "        # 首先判斷 stride 是否為1，輸入通道和輸出通道是否相等。不相等則使用 1 X 1 的卷積改變大小和通道\n",
    "        #作為 downsample\n",
    "        # 在 Resnet 中，每層 layer 傳入的 stride =2\n",
    "        if stride != 1 or self.current_in_channels != in_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.current_in_channels, in_channels * block.expansion,\n",
    "                    kernel_size = 1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(in_channels * block.expansion)\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        # 新增第一個 basic block，把 downsample 傳給 BasicBlock 作為降取樣的層。\n",
    "        layers.append(block(self.current_in_channels, in_channels, stride=stride, downsample=downsample))\n",
    "        \n",
    "        # 修改輸出的通道數\n",
    "        self.current_in_channels = in_channels * block.expansion\n",
    "        \n",
    "        # 繼續新增這個 layer 裡接下來的 BasicBlock\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.current_in_channels, in_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.first(x)\n",
    "        for i in range(len(self.layers)):\n",
    "            x = getattr(self, 'layer'+str(i+1))(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 兩個 3*3 前後的維度相同\n",
    "class BasicBlock(nn.Module):\n",
    "    '''\n",
    "    x = (in, H, W) -> conv2d -> (out, H, W) -> conv2d -> (out, H, W) + x\n",
    "    '''\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, kernel_size=3, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        padding = int(kernel_size/2)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, \n",
    "                kernel_size=kernel_size, padding=padding, stride=stride, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            self.activation,\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                out_channels, out_channels, \n",
    "                kernel_size=kernel_size, padding=padding, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        #x 賦值給 residual，用於後面的 shortcut 連線\n",
    "        out = self.block(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            #遇到降維或升維時要保證能夠相加\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out += residual\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottleneck：三個卷基層分别是1x1，3x3，1x1，分别用来降低维度，卷積處理，提高维度\n",
    "# 目的是 -> 减少參數數量，Bottleneck相比较BasicBlock在参数的数目上較少但經度差不多\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    '''\n",
    "    x = (in, H, W) -> conv2d(1x1) -> conv2d -> (out, H, W) -> conv2d(1x1) -> (out*4, H, W) + x \n",
    "    '''\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, kernel_size=3, downsample=None):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        padding = int(kernel_size/2)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            # 1x1 的卷積是為了降維，減少通道數\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            self.activation,\n",
    "            # 3x3 的卷積是為了改變圖片大小，不改變通道數\n",
    "            nn.Conv2d(\n",
    "                out_channels, out_channels,\n",
    "                kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            self.activation,\n",
    "            \n",
    "             # 1x1 的卷積是為了升維，增加通道數，增加到 planes * 4\n",
    "            nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * self.expansion),\n",
    "        )\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block(x)\n",
    "        \n",
    "        #若上一個Residual Block的輸出維度和當前維度不同，則對這個x進行downsample，若維度依樣則直接鄉間(out += residual)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out += residual\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(pretrained=False, **kwargs): \n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    model = ResNet(BottleneckBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, learning_rate, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    Loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    \n",
    "\n",
    "    for batch_idx, (img, label) in enumerate(data_loader):\n",
    "\n",
    "        data, target = img.to(device), label.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = Loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch%1 == 0):    \n",
    "        print(\"-------------------------------------------------\")\n",
    "        print(\"Train Epoch : \", epoch+1, \"    Loss : \", loss.item())\n",
    "        print(\"-------------------------------------------------\")\n",
    "        \n",
    "    return model\n",
    "\n",
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    Loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        test_loss += Loss(output, target).item()\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(data_loader) # loss function already averages over batch size\n",
    "    \n",
    "    print('\\nTest set:  Accuracy: {}/{} ({}%)\\n'.format(correct, len(data_loader.dataset), \n",
    "                                                        100. * correct / len(data_loader.dataset)))\n",
    "    acc = 10000000*correct / len(data_loader.dataset)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def get_predict(model, data_loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        output = output.data.max(1)[1]\n",
    "        output = output.cpu()\n",
    "        output = output.numpy()\n",
    "        y_pred = np.append(y_pred, output)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 28100 images...\n",
      "> Found 7026 images...\n",
      "> dataset with augmentation with[RandomHorizontalFlip(p=0.5), RandomVerticalFlip(p=0.5)]\n",
      "> Found 28100 images...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataloader.RetinopathyLoader('./data', 'train')\n",
    "test_dataset  = dataloader.RetinopathyLoader('./data', 'test')\n",
    "\n",
    "augmentation = [\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "]\n",
    "print(\"> dataset with augmentation with{}\".format(augmentation))\n",
    "\n",
    "train_dataset_with_augementation = dataloader.RetinopathyLoader('./data', 'train', augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    PARAMETER：\n",
    "    For ResNet18\n",
    "\"\"\"\n",
    "\n",
    "Batch_size= 24\n",
    "Learning_rate = 0.001 \n",
    "device = torch.device(\"cuda:0\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=Batch_size)\n",
    "train_aug_loader = DataLoader(train_dataset_with_augementation, batch_size=Batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=Batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "for batch_idx, (data, target) in enumerate(test_loader):     \n",
    "    y_true = np.append(y_true, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For ResNet18 without pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (first): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet18 = resnet18(pretrained=False)\n",
    "ResNet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch no. 1\n"
     ]
    }
   ],
   "source": [
    "Epochs = 10\n",
    "acc_ResNet18 = 0\n",
    "acc_ResNet18_test  = np.zeros(Epochs)\n",
    "acc_ResNet18_train = np.zeros(Epochs)\n",
    "\n",
    "for epoch in range(0, Epochs):\n",
    "    print('Training epoch no.', epoch+1)\n",
    "    ResNet18 = train(ResNet18, train_aug_loader, Learning_rate, epoch)\n",
    "    acc_ResNet18_train[epoch] = test(ResNet18, train_loader)\n",
    "    acc_ResNet18_test[epoch]  = test(ResNet18, test_loader)\n",
    "\n",
    "    if (acc_ResNet18_test[epoch] > acc_ResNet18):\n",
    "        torch.save({'state_dict': ResNet18.state_dict()}, 'model_ResNet18_w0_pre_epoch10_batch24.pth.tar')\n",
    "        \n",
    "        print(\"> New higher accuracy !!! \", acc_ResNet18_test[epoch]/100000)\n",
    "        acc_ResNet18 = acc_ResNet18_test[epoch]\n",
    "    print ('------------------------------------------------------------------------')\n",
    "\n",
    "# torch.save({'state_dict': ResNet18.state_dict()}, 'model_ResNet18_w0_pre_epoch10_batch24_final.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model_ResNet18_w0_pre_epoch10_batch24.pth.tar')\n",
    "ResNet18.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "acc_ResNet18 = test(ResNet18, test_loader)\n",
    "acc_ResNet18_float = acc_ResNet18.item() / 100000\n",
    "\n",
    "\n",
    "print ('------------------------------------------------------------------------')\n",
    "print ('Highest accuracy for ResNet18 without pretrained : {} %'.format(acc_ResNet18_float))\n",
    "print ('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "y_ResNet18_without = get_predict(ResNet18, test_loader)\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_true, y_ResNet18_without, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store acc_ResNet18_test, acc_ResNet18_train to csv\n",
    "acc_ResNet18_train_float = np.zeros(len(acc_ResNet18_train))\n",
    "acc_ResNet18_test_float = np.zeros(len(acc_ResNet18_test))\n",
    "for i in range(len(acc_ResNet18_test)):\n",
    "    acc_ResNet18_test_float[i] = acc_ResNet18_test[i]/100000\n",
    "    acc_ResNet18_train_float[i] = acc_ResNet18_train[i]/100000\n",
    "pd.DataFrame(acc_ResNet18_test_float).to_csv(\"result/ResNet18_test_epoch10_batch24.csv\")\n",
    "pd.DataFrame(acc_ResNet18_train_float).to_csv(\"result/ResNet18_train_epoch10_batch24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ResNet18\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet18_pretrained = models.resnet18(pretrained=True)\n",
    "fc_features = ResNet18_pretrained.fc.in_features\n",
    "ResNet18_pretrained.fc = nn.Linear(fc_features, 5)\n",
    "ResNet18_pretrained.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 10\n",
    "acc_ResNet18_pretrained = 0\n",
    "acc_ResNet18_pretrained_test  = np.zeros(Epochs)\n",
    "acc_ResNet18_pretrained_train = np.zeros(Epochs)\n",
    "\n",
    "for epoch in range(0, Epochs):\n",
    "    print('Training epoch no.', epoch+1)\n",
    "    ResNet18_pretrained = train(ResNet18_pretrained, train_loader, Learning_rate, epoch)\n",
    "    acc_ResNet18_pretrained_test[epoch] = test(ResNet18_pretrained, test_loader)\n",
    "    \n",
    "    if (acc_ResNet18_pretrained_test[epoch] > acc_ResNet18_pretrained):\n",
    "        torch.save({'state_dict': ResNet18_pretrained.state_dict()}, 'model_ResNet18_pretrained_epoch10_batch24.pth.tar')\n",
    "        print(\"New higher accuracy!!\",acc_ResNet18_pretrained_test[epoch])\n",
    "        acc_ResNet18_pretrained = acc_ResNet18_pretrained_test[epoch]\n",
    "    print ('------------------------------------------------------------------------')\n",
    "torch.save({'state_dict': ResNet18_pretrained.state_dict()}, 'model_ResNet18_pretrained_epoch10_batch24_final.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model_ResNet18_pretrained_epoch10_batch24.pth.tar')\n",
    "ResNet18_pretrained.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "acc_ResNet18_pretrained = test(ResNet18_pretrained, test_loader)\n",
    "acc_ResNet18_pretrained_float = acc_ResNet18_pretrained.item() / 100000\n",
    "\n",
    "\n",
    "print ('------------------------------------------------------------------------')\n",
    "print ('Highest accuracy for ResNet18 with pretrained : {} %'.format(acc_ResNet18_pretrained_float))\n",
    "print ('------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ResNet18_with = get_predict(ResNet18_pretrained, test_loader)\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_true, y_ResNet18_with, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store acc_ResNet18_pretrained_test to csv\n",
    "acc_ResNet18_pretrained_test_float = np.zeros(len(acc_ResNet18_pretrained_test))\n",
    "acc_ResNet18_pretrained_train_float = np.zeros(len(acc_ResNet18_pretrained_train))\n",
    "\n",
    "for i in range(len(acc_ResNet18_pretrained_test)):\n",
    "    acc_ResNet18_pretrained_test_float[i]  = acc_ResNet18_pretrained_test[i]/100000\n",
    "    acc_ResNet18_pretrained_train_float[i] = acc_ResNet18_pretrained_train[i]/100000\n",
    "    \n",
    "pd.DataFrame(acc_ResNet18_pretrained_test_float).to_csv(\"result/ResNet18_pretrained_test_epoch10_batch24.csv\")\n",
    "pd.DataFrame(acc_ResNet18_pretrained_train_float).to_csv(\"result/ResNet18_pretrained_train_epoch10_batch24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ResNet18_pretrained\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    PARAMETER\n",
    "    For ResNet50\n",
    "\"\"\"\n",
    "Batch_size= 10\n",
    "Learning_rate = 0.001 \n",
    "device = torch.device(\"cuda:1\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For ResNet50 wothout pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50 = resnet50(pretrained=False)\n",
    "ResNet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 5\n",
    "acc_ResNet50 = 0\n",
    "acc_ResNet50_test = np.zeros(Epochs)\n",
    "acc_ResNet50_train = np.zeros(Epochs)\n",
    "\n",
    "for epoch in range(0, Epochs):\n",
    "    print('Training epoch no.', epoch+1)\n",
    "    ResNet50 = train(ResNet50, train_aug_loader, Learning_rate, epoch)\n",
    "    acc_ResNet50_train[epoch] = test(ResNet50, train_loader)\n",
    "    acc_ResNet50_test[epoch]  = test(ResNet50, test_loader)\n",
    "    \n",
    "    if (acc_ResNet50_test[epoch] > acc_ResNet50):\n",
    "        torch.save({'state_dict': ResNet50.state_dict()}, 'model_ResNet50_w0_pre_epoch5_batch10.pth.tar')\n",
    "        \n",
    "        print(\"New higher accuracy!!\",acc_ResNet50_test[epoch]/100000)\n",
    "        acc_ResNet50 = acc_ResNet50_test[epoch]\n",
    "    print ('------------------------------------------------------------------------')\n",
    "    \n",
    "# torch.save({'state_dict': ResNet50.state_dict()}, 'model_ResNet50_w0_pre_epoch5_batch10_final.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model_ResNet50_w0_pre_epoch5_batch10.pth.tar')\n",
    "ResNet50.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "acc_ResNet50 = test(ResNet50, test_loader)\n",
    "acc_ResNet50_float = acc_ResNet50.item() / 100000\n",
    "\n",
    "\n",
    "print ('------------------------------------------------------------------------')\n",
    "print ('Highest accuracy for ResNet50 without pretrained : {} %'.format(acc_ResNet50_float))\n",
    "print ('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ResNet50_without = get_predict(ResNet50, test_loader)\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_true, y_ResNet50_without, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store acc_ResNet50_test, acc_ResNet50_trainto csv\n",
    "acc_ResNet50_test_float = np.zeros(len(acc_ResNet50_test))\n",
    "acc_ResNet50_train_float = np.zeros(len(acc_ResNet50_train))\n",
    "\n",
    "for i in range(len(acc_ResNet50_test)):\n",
    "    acc_ResNet50_test_float[i] = acc_ResNet50_test[i]/100000\n",
    "    acc_ResNet50_train_float[i] = acc_ResNet50_train[i]/100000\n",
    "    \n",
    "pd.DataFrame(acc_ResNet50_test_float).to_csv(\"result/ResNet50_test_epoch5_batch10.csv\")\n",
    "pd.DataFrame(acc_ResNet50_train_float).to_csv(\"result/ResNet50_train_epoch5_batch10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ResNet50\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For ResNet50 with pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_pretrained = models.resnet50(pretrained=True)\n",
    "fc_features = ResNet50_pretrained.fc.in_features\n",
    "ResNet50_pretrained.fc = nn.Linear(fc_features, 5)\n",
    "ResNet50_pretrained.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 5\n",
    "acc_ResNet50_pretrained = 0\n",
    "acc_ResNet50_pretrained_test  = np.zeros(Epochs)\n",
    "acc_ResNet50_pretrained_train = np.zeros(Epochs)\n",
    "\n",
    "for epoch in range(0, Epochs):\n",
    "    print('Training epoch no.', epoch+1)\n",
    "    ResNet50_pretrained = train(ResNet50_pretrained, train_aug_loader, Learning_rate, epoch)\n",
    "    acc_ResNet50_pretrained_train[epoch] = test(ResNet50_pretrained, train_loader)\n",
    "    acc_ResNet50_pretrained_test[epoch]  = test(ResNet50_pretrained, test_loader)\n",
    "    \n",
    "    if (acc_ResNet50_pretrained_test[epoch] > acc_ResNet50_pretrained):\n",
    "        torch.save({'state_dict': ResNet50_pretrained.state_dict()}, 'model_ResNet50_pretrained_epoch5_batch10.pth.tar')\n",
    "        print(\"New higher accuracy!!\",acc_ResNet50_pretrained_test[epoch]/100000)\n",
    "        acc_ResNet50_pretrained = acc_ResNet50_pretrained_test[epoch]\n",
    "    print ('------------------------------------------------------------------------')\n",
    "# torch.save({'state_dict': ResNet50_pretrained.state_dict()}, 'model_ResNet50_pretrained_epoch5_batch10_final.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model_ResNet50_pretrained_epoch5_batch10.pth.tar')\n",
    "ResNet50_pretrained.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "acc_ResNet50_pretrained = test(ResNet50_pretrained, test_loader)\n",
    "acc_ResNet50_pretrained_float = acc_ResNet50_pretrained.item() / 100000\n",
    "\n",
    "print ('------------------------------------------------------------------------')\n",
    "print ('Highest accuracy for ResNet50 with pretrained : {} %'.format(acc_ResNet50_pretrained_float))\n",
    "print ('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ResNet50_pre = get_predict(ResNet50_pretrained, test_loader)\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_true, y_ResNet50_pre, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store acc_ResNet50_pretrained_test, acc_ResNet50_pretrained_train to csv\n",
    "acc_ResNet50_pretrained_train_float = np.zeros(len(acc_ResNet50_pretrained_train))\n",
    "acc_ResNet50_pretrained_test_float = np.zeros(len(acc_ResNet50_pretrained_test))\n",
    "\n",
    "for i in range(len(acc_ResNet50_pretrained_test)):\n",
    "    acc_ResNet50_pretrained_test_float[i]  = acc_ResNet50_pretrained_test[i]/100000\n",
    "    acc_ResNet50_pretrained_train_float[i] = acc_ResNet50_pretrained_train[i]/100000\n",
    "    \n",
    "pd.DataFrame(acc_ResNet50_pretrained_test_float).to_csv(\"result/ResNet50_pretrained_test_epoch5_batch10.csv\")\n",
    "pd.DataFrame(acc_ResNet50_pretrained_train_float).to_csv(\"result/ResNet50_pretrained_train_epoch5_batch10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ResNet50_pretrained\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(df):\n",
    "    df_np = df.to_numpy()\n",
    "    df_np_col = df_np[:,1]\n",
    "    del df_np\n",
    "    for i in range(len(df_np_col)):\n",
    "        df_np_col[i]  = df_np_col[i]/100\n",
    "    return df_np_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet18_w0_pre_test_epoch10 = pd.read_csv('/home/shaowen0213/IOC_DLP_110/Lab04/result/ResNet18_test_epoch10_batch20.csv') \n",
    "ResNet18_w0_pre_train_epoch10 = pd.read_csv('/home/shaowen0213/IOC_DLP_110/Lab04/result/ResNet18_train_epoch10_batch20.csv')\n",
    "ResNet18_pretrained_test_epoch10 = pd.read_csv('/home/shaowen0213/IOC_DLP_110/Lab04/result/ResNet18_pretrained_test_epoch10_batch20.csv')\n",
    "ResNet18_pretrained_train_epoch10 = pd.read_csv('/home/shaowen0213/IOC_DLP_110/Lab04/result/ResNet18_pretrained_train_epoch10_batch20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet18_w0_pre_test_epoch10 = to_float(ResNet18_w0_pre_test_epoch10)\n",
    "ResNet18_w0_pre_train_epoch10 = to_float(ResNet18_w0_pre_train_epoch10)\n",
    "ResNet18_pretrained_test_epoch10 = to_float(ResNet18_pretrained_test_epoch10)\n",
    "ResNet18_pretrained_train_epoch10 = to_float(ResNet18_pretrained_train_epoch10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(ResNet18_w0_pre_test_epoch10)\n",
    "plt.plot(ResNet18_w0_pre_train_epoch10)\n",
    "plt.plot(ResNet18_pretrained_test_epoch10)\n",
    "plt.plot(ResNet18_pretrained_train_epoch10)\n",
    "\n",
    "plt.hlines(0.82, 0, 10, colors = \"gray\", linestyles = \"dashed\")\n",
    "plt.hlines(0.8, 0, 10, colors = \"gray\", linestyles = \"dashed\")\n",
    "plt.hlines(0.75, 0, 10, colors = \"gray\", linestyles = \"dashed\")\n",
    "\n",
    "\n",
    "plt.title('ResNet18 comparison')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['ResNet18 without pretrain_train data', 'ResNet18 without pretrain_test data',\n",
    "            'ResNet18 with pretrain_train data', 'ResNet18 with pretrain_test data'], loc=2, bbox_to_anchor=(1.05,1.0),borderaxespad = 0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_test_epoch5_batch10 = pd.read_csv('/home/shaowen0213/IOC_DLP_110/Lab04/result/ResNet50_test_epoch5_batch10.csv') \n",
    "ResNet50_train_epoch5_batch10 = pd.read_csv('/home/shaowen0213/IOC_DLP_110/Lab04/result/ResNet50_train_epoch5_batch10.csv')\n",
    "ResNet50_pretrained_test_epoch5_batch10 = pd.read_csv('/home/shaowen0213/IOC_DLP_110/Lab04/result/ResNet50_pretrained_test_epoch5_batch10.csv')\n",
    "ResNet50_pretrained_train_epoch5_batch10 = pd.read_csv('/home/shaowen0213/IOC_DLP_110/Lab04/result/ResNet50_pretrained_train_epoch5_batch10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_test_epoch5_batch10 = to_float(ResNet50_test_epoch5_batch10)\n",
    "ResNet50_train_epoch5_batch10 = to_float(ResNet50_train_epoch5_batch10)\n",
    "ResNet50_pretrained_test_epoch5_batch10 = to_float(ResNet50_pretrained_test_epoch5_batch10)\n",
    "ResNet50_pretrained_train_epoch5_batch10 = to_float(ResNet50_pretrained_train_epoch5_batch10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(ResNet50_test_epoch5_batch10)\n",
    "plt.plot(ResNet50_train_epoch5_batch10)\n",
    "plt.plot(ResNet50_pretrained_test_epoch5_batch10)\n",
    "plt.plot(ResNet50_pretrained_train_epoch5_batch10)\n",
    "\n",
    "plt.hlines(0.82, 0, 5, colors = \"gray\", linestyles = \"dashed\")\n",
    "plt.hlines(0.8, 0, 5, colors = \"gray\", linestyles = \"dashed\")\n",
    "plt.hlines(0.75, 0, 5, colors = \"gray\", linestyles = \"dashed\")\n",
    "\n",
    "\n",
    "plt.title('ResNet50 comparison')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['ResNet50 without pretrain_train data', 'ResNet50 without pretrain_test data',\n",
    "            'ResNet50 with pretrain_train data', 'ResNet50 with pretrain_test data'], \n",
    "           loc=2, bbox_to_anchor=(1.05,1.0),borderaxespad = 0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from texttable import Texttable\n",
    "print(\"     ResNet18, ResNet50 Highest result     \")\n",
    "print(\"> ResNet18 with epoch:10, batch_size:20 \")\n",
    "print(\"> ResNet50 with epoch:05, batch_size:10 \")\n",
    "tb=Texttable()\n",
    "tb.set_cols_align(['l', 'c', 'c'])\n",
    "tb.set_cols_dtype(['t', 'f', 'f'])\n",
    "tb.add_rows([['Net', 'without pretrained', 'with pretrained'],\n",
    "            [\"ResNet18\", np.max(ResNet18_w0_pre_test_epoch10), np.max(ResNet18_pretrained_test_epoch10)],\n",
    "            [\"ResNet50\", np.max(ResNet50_test_epoch5_batch10),  np.max(ResNet50_pretrained_train_epoch5_batch10)],\n",
    "            ])\n",
    "print(tb.draw())\n",
    "\n",
    "\n",
    "# tb.add_rows(df.values, header=False)\n",
    "# # tb.add_rows(['Net', 'ReLU', 'Leaky ReLU', 'ELU'])\n",
    "# print(tb.draw())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
