{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import pyprind\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import model_zoo\n",
    "import dataloader\n",
    "import scikitplot as skplt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=5, start_in_channels=64):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.current_in_channels = start_in_channels\n",
    "        \n",
    "        self.first = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                3, self.current_in_channels,\n",
    "                kernel_size=7, stride=2, padding=3, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(self.current_in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.layers = layers\n",
    "        channels = self.current_in_channels\n",
    "        for i, l in enumerate(layers):\n",
    "            setattr(self, 'layer'+str(i+1), \n",
    "                    self._make_layer(block, channels, l, stride=(2 if i!=0 else 1) ))\n",
    "            channels*=2\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(self.current_in_channels, num_classes)\n",
    "            \n",
    "    def _make_layer(self, block, in_channels, blocks, stride=1):\n",
    "        downsample=None\n",
    "        # 首先判斷 stride 是否為1，輸入通道和輸出通道是否相等。不相等則使用 1 X 1 的卷積改變大小和通道\n",
    "        #作為 downsample\n",
    "        # 在 Resnet 中，每層 layer 傳入的 stride =2\n",
    "        if stride != 1 or self.current_in_channels != in_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.current_in_channels, in_channels * block.expansion,\n",
    "                    kernel_size = 1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(in_channels * block.expansion)\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        # 新增第一個 basic block，把 downsample 傳給 BasicBlock 作為降取樣的層。\n",
    "        layers.append(block(self.current_in_channels, in_channels, stride=stride, downsample=downsample))\n",
    "        \n",
    "        # 修改輸出的通道數\n",
    "        self.current_in_channels = in_channels * block.expansion\n",
    "        \n",
    "        # 繼續新增這個 layer 裡接下來的 BasicBlock\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.current_in_channels, in_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.first(x)\n",
    "        for i in range(len(self.layers)):\n",
    "            x = getattr(self, 'layer'+str(i+1))(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 兩個 3*3 前後的維度相同\n",
    "class BasicBlock(nn.Module):\n",
    "    '''\n",
    "    x = (in, H, W) -> conv2d -> (out, H, W) -> conv2d -> (out, H, W) + x\n",
    "    '''\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, kernel_size=3, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        padding = int(kernel_size/2)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, \n",
    "                kernel_size=kernel_size, padding=padding, stride=stride, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            self.activation,\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                out_channels, out_channels, \n",
    "                kernel_size=kernel_size, padding=padding, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        #x 賦值給 residual，用於後面的 shortcut 連線\n",
    "        out = self.block(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            #遇到降維或升維時要保證能夠相加\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out += residual\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottleneck：三個卷基層分别是1x1，3x3，1x1，分别用来降低维度，卷積處理，提高维度\n",
    "# 目的是 -> 减少參數數量，Bottleneck相比较BasicBlock在参数的数目上較少但經度差不多\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    '''\n",
    "    x = (in, H, W) -> conv2d(1x1) -> conv2d -> (out, H, W) -> conv2d(1x1) -> (out*4, H, W) + x \n",
    "    '''\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, kernel_size=3, downsample=None):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        padding = int(kernel_size/2)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            # 1x1 的卷積是為了降維，減少通道數\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            self.activation,\n",
    "            # 3x3 的卷積是為了改變圖片大小，不改變通道數\n",
    "            nn.Conv2d(\n",
    "                out_channels, out_channels,\n",
    "                kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            self.activation,\n",
    "            \n",
    "             # 1x1 的卷積是為了升維，增加通道數，增加到 planes * 4\n",
    "            nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * self.expansion),\n",
    "        )\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block(x)\n",
    "        \n",
    "        #若上一個Residual Block的輸出維度和當前維度不同，則對這個x進行downsample，若維度依樣則直接鄉間(out += residual)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out += residual\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(pretrained=False, **kwargs): \n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    model = ResNet(BottleneckBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, learning_rate, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    Loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    \n",
    "\n",
    "    for batch_idx, (img, label) in enumerate(data_loader):\n",
    "\n",
    "        data, target = img.to(device), label.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = Loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch%1 == 0):    \n",
    "        print(\"-------------------------------------------------\")\n",
    "        print(\"Train Epoch : \", epoch+1, \"    Loss : \", loss.item())\n",
    "        print(\"-------------------------------------------------\")\n",
    "        \n",
    "    return model\n",
    "\n",
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    Loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        test_loss += Loss(output, target).item()\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(data_loader) # loss function already averages over batch size\n",
    "    \n",
    "    print('\\nTest set:  Accuracy: {}/{} ({}%)\\n'.format(correct, len(data_loader.dataset), \n",
    "                                                        100. * correct / len(data_loader.dataset)))\n",
    "    acc = 10000000*correct / len(data_loader.dataset)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def get_predict(model, data_loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        output = output.data.max(1)[1]\n",
    "        output = output.cpu()\n",
    "        output = output.numpy()\n",
    "        y_pred = np.append(y_pred, output)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 28100 images...\n",
      "> Found 7026 images...\n",
      "> dataset with augmentation with[RandomHorizontalFlip(p=0.5), RandomVerticalFlip(p=0.5)]\n",
      "> Found 28100 images...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataloader.RetinopathyLoader('./data', 'train')\n",
    "test_dataset  = dataloader.RetinopathyLoader('./data', 'test')\n",
    "\n",
    "augmentation = [\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "]\n",
    "print(\"> dataset with augmentation with{}\".format(augmentation))\n",
    "\n",
    "train_dataset_with_augementation = dataloader.RetinopathyLoader('./data', 'train', augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    PARAMETER：\n",
    "    For ResNet18\n",
    "\"\"\"\n",
    "\n",
    "Batch_size= 32\n",
    "Learning_rate = 0.001 \n",
    "device = torch.device(\"cuda:0\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=Batch_size)\n",
    "train_aug_loader = DataLoader(train_dataset_with_augementation, batch_size=Batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=Batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "for batch_idx, (data, target) in enumerate(test_loader):     \n",
    "    y_true = np.append(y_true, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For ResNet18 without pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (first): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet18 = resnet18(pretrained=False)\n",
    "ResNet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch no. 1\n",
      "-------------------------------------------------\n",
      "Train Epoch :  1     Loss :  0.599854588508606\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20656/28100 (73.50889587402344%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5154/7026 (73.35610961914062%)\n",
      "\n",
      "> New higher accuracy !!!  73.3561\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 2\n",
      "-------------------------------------------------\n",
      "Train Epoch :  2     Loss :  0.5899073481559753\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20655/28100 (73.50534057617188%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5153/7026 (73.34187316894531%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 3\n",
      "-------------------------------------------------\n",
      "Train Epoch :  3     Loss :  0.6282018423080444\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20655/28100 (73.50534057617188%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5152/7026 (73.32763671875%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 4\n",
      "-------------------------------------------------\n",
      "Train Epoch :  4     Loss :  0.5725492835044861\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20655/28100 (73.50534057617188%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5151/7026 (73.31340789794922%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 5\n",
      "-------------------------------------------------\n",
      "Train Epoch :  5     Loss :  0.6142916083335876\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20655/28100 (73.50534057617188%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5153/7026 (73.34187316894531%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 6\n",
      "-------------------------------------------------\n",
      "Train Epoch :  6     Loss :  0.5981339812278748\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20654/28100 (73.50177764892578%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5156/7026 (73.38457489013672%)\n",
      "\n",
      "> New higher accuracy !!!  73.38457\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 7\n",
      "-------------------------------------------------\n",
      "Train Epoch :  7     Loss :  0.6789129972457886\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20657/28100 (73.51245880126953%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5152/7026 (73.32763671875%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 8\n",
      "-------------------------------------------------\n",
      "Train Epoch :  8     Loss :  0.6605528593063354\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20651/28100 (73.49110412597656%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5153/7026 (73.34187316894531%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 9\n",
      "-------------------------------------------------\n",
      "Train Epoch :  9     Loss :  0.6191365718841553\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20650/28100 (73.48754119873047%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5154/7026 (73.35610961914062%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 10\n",
      "-------------------------------------------------\n",
      "Train Epoch :  10     Loss :  0.638611376285553\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20652/28100 (73.49465942382812%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5156/7026 (73.38457489013672%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 11\n",
      "-------------------------------------------------\n",
      "Train Epoch :  11     Loss :  0.6547339558601379\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20651/28100 (73.49110412597656%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5155/7026 (73.3703384399414%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 12\n",
      "-------------------------------------------------\n",
      "Train Epoch :  12     Loss :  0.6810785531997681\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20653/28100 (73.49822235107422%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5151/7026 (73.31340789794922%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 13\n",
      "-------------------------------------------------\n",
      "Train Epoch :  13     Loss :  0.7385971546173096\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20653/28100 (73.49822235107422%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5154/7026 (73.35610961914062%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 14\n",
      "-------------------------------------------------\n",
      "Train Epoch :  14     Loss :  0.7067807912826538\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20652/28100 (73.49465942382812%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5154/7026 (73.35610961914062%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 15\n",
      "-------------------------------------------------\n",
      "Train Epoch :  15     Loss :  0.7466438412666321\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20651/28100 (73.49110412597656%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5153/7026 (73.34187316894531%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 16\n",
      "-------------------------------------------------\n",
      "Train Epoch :  16     Loss :  0.7864223718643188\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 20663/28100 (73.53380584716797%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5157/7026 (73.3988037109375%)\n",
      "\n",
      "> New higher accuracy !!!  73.3988\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Epochs = 16\n",
    "acc_ResNet18 = 0\n",
    "acc_ResNet18_test  = np.zeros(Epochs)\n",
    "acc_ResNet18_train = np.zeros(Epochs)\n",
    "\n",
    "for epoch in range(0, Epochs):\n",
    "    print('Training epoch no.', epoch+1)\n",
    "    ResNet18 = train(ResNet18, train_aug_loader, Learning_rate, epoch)\n",
    "    acc_ResNet18_train[epoch] = test(ResNet18, train_loader)\n",
    "    acc_ResNet18_test[epoch]  = test(ResNet18, test_loader)\n",
    "\n",
    "    if (acc_ResNet18_test[epoch] > acc_ResNet18):\n",
    "        torch.save({'state_dict': ResNet18.state_dict()}, 'model_ResNet18_w0_pre_epoch16_batch32.pth.tar')\n",
    "        \n",
    "        print(\"> New higher accuracy !!! \", acc_ResNet18_test[epoch]/100000)\n",
    "        acc_ResNet18 = acc_ResNet18_test[epoch]\n",
    "    print ('------------------------------------------------------------------------')\n",
    "\n",
    "# torch.save({'state_dict': ResNet18.state_dict()}, 'model_ResNet18_w0_pre_epoch10_batch24_final.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 5157/7026 (73.3988037109375%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Highest accuracy for ResNet18 without pretrained : 73.3988 %\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('model_ResNet18_w0_pre_epoch16_batch32.pth.tar')\n",
    "ResNet18.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "acc_ResNet18 = test(ResNet18, test_loader)\n",
    "acc_ResNet18_float = acc_ResNet18.item() / 100000\n",
    "\n",
    "\n",
    "print ('------------------------------------------------------------------------')\n",
    "print ('Highest accuracy for ResNet18 without pretrained : {} %'.format(acc_ResNet18_float))\n",
    "print ('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f292de96358>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the confusion matrix\n",
    "y_ResNet18_without = get_predict(ResNet18, test_loader)\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_true, y_ResNet18_without, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store acc_ResNet18_test, acc_ResNet18_train to csv\n",
    "acc_ResNet18_train_float = np.zeros(len(acc_ResNet18_train))\n",
    "acc_ResNet18_test_float = np.zeros(len(acc_ResNet18_test))\n",
    "for i in range(len(acc_ResNet18_test)):\n",
    "    acc_ResNet18_test_float[i] = acc_ResNet18_test[i]/100000\n",
    "    acc_ResNet18_train_float[i] = acc_ResNet18_train[i]/100000\n",
    "pd.DataFrame(acc_ResNet18_test_float).to_csv(\"result/ResNet18_test_epoch16_batch32.csv\")\n",
    "pd.DataFrame(acc_ResNet18_train_float).to_csv(\"result/ResNet18_train_epoch16_batch32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ResNet18\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet18_pretrained = models.resnet18(pretrained=True)\n",
    "fc_features = ResNet18_pretrained.fc.in_features\n",
    "ResNet18_pretrained.fc = nn.Linear(fc_features, 5)\n",
    "ResNet18_pretrained.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch no. 1\n",
      "-------------------------------------------------\n",
      "Train Epoch :  1     Loss :  0.6639693975448608\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 21964/28100 (78.16370391845703%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5406/7026 (76.94278717041016%)\n",
      "\n",
      "New higher accuracy!! 7694278.0\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 2\n",
      "-------------------------------------------------\n",
      "Train Epoch :  2     Loss :  0.5649436712265015\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 22523/28100 (80.15302276611328%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5550/7026 (78.99231719970703%)\n",
      "\n",
      "New higher accuracy!! 7899231.0\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 3\n",
      "-------------------------------------------------\n",
      "Train Epoch :  3     Loss :  0.8949469923973083\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 22820/28100 (81.2099609375%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5584/7026 (79.47623443603516%)\n",
      "\n",
      "New higher accuracy!! 7947623.0\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 4\n",
      "-------------------------------------------------\n",
      "Train Epoch :  4     Loss :  0.9818096160888672\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 23002/28100 (81.85765075683594%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5626/7026 (80.07401275634766%)\n",
      "\n",
      "New higher accuracy!! 8007401.0\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 5\n",
      "-------------------------------------------------\n",
      "Train Epoch :  5     Loss :  0.7032445669174194\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 23233/28100 (82.67971801757812%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5658/7026 (80.52946472167969%)\n",
      "\n",
      "New higher accuracy!! 8052946.0\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 6\n",
      "-------------------------------------------------\n",
      "Train Epoch :  6     Loss :  0.6209762692451477\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 23407/28100 (83.29893493652344%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5682/7026 (80.87104797363281%)\n",
      "\n",
      "New higher accuracy!! 8087105.0\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 7\n",
      "-------------------------------------------------\n",
      "Train Epoch :  7     Loss :  0.4935853183269501\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 23370/28100 (83.1672592163086%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5685/7026 (80.91374969482422%)\n",
      "\n",
      "New higher accuracy!! 8091374.0\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 8\n",
      "-------------------------------------------------\n",
      "Train Epoch :  8     Loss :  0.6056709885597229\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 23785/28100 (84.64412689208984%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5688/7026 (80.9564437866211%)\n",
      "\n",
      "New higher accuracy!! 8095644.0\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 9\n",
      "-------------------------------------------------\n",
      "Train Epoch :  9     Loss :  0.9519443511962891\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 23413/28100 (83.32028198242188%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5544/7026 (78.90691375732422%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training epoch no. 10\n",
      "-------------------------------------------------\n",
      "Train Epoch :  10     Loss :  0.7491068243980408\n",
      "-------------------------------------------------\n",
      "\n",
      "Test set:  Accuracy: 23910/28100 (85.0889663696289%)\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 5685/7026 (80.91374969482422%)\n",
      "\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Epochs = 10\n",
    "acc_ResNet18_pretrained = 0\n",
    "acc_ResNet18_pretrained_test  = np.zeros(Epochs)\n",
    "acc_ResNet18_pretrained_train = np.zeros(Epochs)\n",
    "\n",
    "for epoch in range(0, Epochs):\n",
    "    print('Training epoch no.', epoch+1)\n",
    "    ResNet18_pretrained = train(ResNet18_pretrained, train_aug_loader, Learning_rate, epoch)\n",
    "    acc_ResNet18_pretrained_train[epoch] = test(ResNet18_pretrained, train_loader)\n",
    "    acc_ResNet18_pretrained_test[epoch] = test(ResNet18_pretrained, test_loader)\n",
    "    \n",
    "    if (acc_ResNet18_pretrained_test[epoch] > acc_ResNet18_pretrained):\n",
    "        torch.save({'state_dict': ResNet18_pretrained.state_dict()}, 'model_ResNet18_pretrained_epoch16_batch32.pth.tar')\n",
    "        print(\"New higher accuracy!!\",acc_ResNet18_pretrained_test[epoch])\n",
    "        acc_ResNet18_pretrained = acc_ResNet18_pretrained_test[epoch]\n",
    "    print ('------------------------------------------------------------------------')\n",
    "# torch.save({'state_dict': ResNet18_pretrained.state_dict()}, 'model_ResNet18_pretrained_epoch16_batch32_final.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 5688/7026 (80.9564437866211%)\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Highest accuracy for ResNet18 with pretrained : 80.95644 %\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('model_ResNet18_pretrained_epoch16_batch32.pth.tar')\n",
    "ResNet18_pretrained.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "acc_ResNet18_pretrained = test(ResNet18_pretrained, test_loader)\n",
    "acc_ResNet18_pretrained_float = acc_ResNet18_pretrained.item() / 100000\n",
    "\n",
    "\n",
    "print ('------------------------------------------------------------------------')\n",
    "print ('Highest accuracy for ResNet18 with pretrained : {} %'.format(acc_ResNet18_pretrained_float))\n",
    "print ('------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f292de33898>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEWCAYAAAAQBZBVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3wU1fr48c+TRoeE0FLoNYROKAoIgiCQUKRLE9DrvV7li+Xen1iueLGhKJarXsUrIggiRToKKmKnK0pRaUESAkiAgFJCNs/vj5mE9GxgJ9mQ8/Y1L7MzZ888O+w+e+bMzjmiqhiGYZQ0PkUdgGEYRlEwyc8wjBLJJD/DMEokk/wMwyiRTPIzDKNEMsnPMIwSySS/YkREHheR9+y/a4nIHyLi6+F9xIrITZ6sswD7flJETojI0auow5HjUthE5GER+V9Rx3EtM8kvA/uDf1xEymVYd4eIbCjCsHKkqr+panlVdRXmfkWkvYisEZHTInJSRDaLyHgP1FsLeABoqqo1rrQeJ4+LiKj9/vDLsM7fXufWD2ZFpJuIxOVXTlWfVtU7riZeI28m+WXnC0y62krEck0dXxG5DlgPfAE0AIKBu4A+Hqi+FpCoqsc9UJeTTpH59fax13lMxuRqOOea+nB6yHTgHyISmNNGEbleRLaISJL9/+szbNsgIk+JyDfAOaCeve5JEfnWPh1bKSLBIjJPRM7YddTJUMfLInLY3rZNRLrkEkcduyXiJyLX2XWnLRdEJNYu5yMik0Vkv4gkishCEamcoZ4xInLI3vaIG8fmXVV9VlVPqGWbqg7LUN9fRGSf3SpcISKhGbapiPxNRPbaLcfX7C+Jm4BPgFA7/tk5tZAynpLbLdCt9nE6JiIzsh4X+3GoHcdJO66/ZKjvcft4zBGRsyKyS0Si8jkGc4GxGR6PBeZkiXO8iOy